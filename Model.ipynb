{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, n_layers, batch_size, seq_len, batch_first = True):\n",
    "        super(Model, self).__init__()\n",
    "        self.LSTM = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first)\n",
    "        self.inp = torch.randn(batch_size, seq_len, input_dim)\n",
    "        \n",
    "        #We'll have to initialize a hidden state and cell state for the LSTM as this is the first cell.\n",
    "        #The hidden state and cell state is stored in a tuple with the format (hidden_state, cell_state).\n",
    "        self.hidden_state = torch.randn(n_layers, batch_size, hidden_dim)\n",
    "        self.cell_state = torch.randn(n_layers, batch_size, hidden_dim)\n",
    "        self.hidden = (self.hidden_state, self.cell_state)\n",
    "        \n",
    "    def many_to_one(self):\n",
    "        out, hidden = self.LSTM(self.inp, self.hidden)\n",
    "        return out, hidden\n",
    "        \n",
    "    \n",
    "    def many_to_many(self, out):\n",
    "        out = out.squeeze()[-1, :]\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 5 #Input dimension: represents the size of the input at each time step. \n",
    "hidden_dim = 10 #Hidden dimension: represents the size of the hidden state and cell state at each time step.\n",
    "n_layers = 1 #The number of LSTM layers stacked on top of eachother."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_data(df, train = .8):\n",
    "    mask = int(len(df)*train)\n",
    "    x_train = df[~mask:]\n",
    "    x_valid = df[mask:]\n",
    "    return x_train, x_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data):\n",
    "    def normalize(x, mean, std):\n",
    "        return (x - mean)/std\n",
    "    mean, std = data.mean(), data.std()\n",
    "    return normalize(data, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid shape: (1966, 67)\n",
      "Train shape: (7861, 67)\n",
      "Train: -0.00018249649851901698 xnorm_train:  -0.05635635223120648\n",
      "Valid: 0.00689957444836972 xnorm_valid:  0.7732659611356497\n"
     ]
    }
   ],
   "source": [
    "PATH = os.path.abspath(\"ucsbdata.csv\")\n",
    "df = pd.read_csv(PATH)\n",
    "df = df[df[\"R\"].notna()]\n",
    "del df[\"Index\"]\n",
    "#df = df.fillna(0)\n",
    "x_train, x_valid = organize_data(df)\n",
    "xnorm_train = normalize_data(x_train)\n",
    "xnorm_valid = normalize_data(x_valid)\n",
    "print(\"Valid shape:\", x_valid.shape)\n",
    "print(\"Train shape:\", x_train.shape)\n",
    "print(\"Train:\", x_train.iloc[0, 0], \"xnorm_train: \", xnorm_train.iloc[0, 0])\n",
    "print(\"Valid:\", x_valid.iloc[0, 0], \"xnorm_valid: \", xnorm_valid.iloc[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
